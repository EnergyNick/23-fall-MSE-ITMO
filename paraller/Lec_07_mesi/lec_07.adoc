= Тема-загадка 

Метафора системы (окружение): 

* Одна обычная серверная система: 8 ядер core i7, 64 гб памяти, Linux (def v3.14)
* Крутиться одно приложение. Технология разработки: c++, qute (не в графики, а в машине состояний), boost, openCV, math, pcap... 
* В прилжении примерно 10 выч потоков. Штатная загрузка 6 ядер на 100%, 12 Гб
* Назначение -- подключено утсройство с камерами. Их задача -- елси что-то пролетает мимо -- автоматически детектировать и сопровождать. (Наблюдение за птицами). Можно управлять камерами. Соединена по utp 1 gb/sec по витой паре. 
* Ограничение на производительность: скорость работы сервиса обеспечивает то, что если объект пролетает по диагонали камеры -- он это делает за 1/4 секунды.
* Есть десктопная штука для оператора с каким-то управляющим воздействием на сервер, которые потом транслируются дальше. TCP/IP


Проблема: случайно раз в среднем раз сутки видео зависает и все (оператор перестает видеть). Зависает на бесконечное время, если ничего не делать. После перезагрузки сервера чинится. Если перезагрузить клиента, то мы вообще ничего не получаем.

Цель: сделать, чтобы система работала.

Попытки ("мы можем все, мы разработчики")

* если пинговать -- сервер не отвечает. При этом можно подключиться к серверу по ssh.
* идет ли поток с камеры? посмтореть на сервере через sudo wireshark
* автоматическое управление камеры перестает работать
* если посмтореть последние 30 секунд перед зависанием -- ничего необычного не обнаружено
* *htop -- после зависания процесс на сервере находится в списке процессов, потребление ОП такое же как обычно*
* *подключимся к процессу через gdb. Как только подключились -- все заработало.*
* есть система журналирования. когда система зависает -- логи не пишутся, никаких сообщений о чем-то необычном нет.
* после зависания сетевые сервисы не закрываются.
* есть ли паразитные службы, которые на это влияют (антивирус и т.д.). все идеально, ничего не влияет.
* запустить на одном ядре командой линукса. все работает, никаких зависаний нет. НО не удовлетворяем правилам производительности никак.
* зайдем на сервер, посмотрим состояние потоков (sleep/wait) в htop (State).Смотрим на все потоки службы. Смотрим с частотой 25 Гц. Поэтому чисто статистически можем не поймать deadlock. Смотрим на проценсс cpu. У 4 не 0.
* (3 ч/нед) Статический анализ кода: sonar, c++check, cpplint, pvsstudio -- все идеально, никаких проблем.
* (1 ч/нед) Заставим разработчика изучить документацию gdb. Изучает неделю. Даже понял. С нашей проблемой связать не смог.
* Есть кастомные обработчики сигналов для работы с камерами.
* Картинки отправляются брокеру обмена сообщений, оттуда берет тот, кому это нужно. 
* (2 ч/нед) комплексное тестирования видео -- написать имитатор видео, прогнать на разной ситуации. Разработали.
* *под валгриндом все отлично работает (нет дед и лайв локов), только не укладываемся во время*
* (1 ч/нед) меняем с Astra linux 3.14 на RedOS 6.1. проверить баг с tcp, проблем нет
* (3 ч/мес) РЕализовать новый протокол с гарантированной доставкой 
* отключим нейронку. зависло.
* запустим на железе мощнее. зависает. запускаем на железе поменьше -- не зависает. 
* (1 ч/день) обрабатываем видео в одно потоке. без обработки. иногда зависает раз в месяц. если оставить одну камеру, то будет то же самое.
* запустим положение под strace (sys call trace) -- трассировка системных вызовов. Позволяет встроится между процессом и ядром ОС. Можем видеть все вызовы с параметрами и возвращаемыми значениями. Запустим для текстового редактора -- все они отражаются в `poll`. Можно подключиться к живому процессу. Он сразу начинает работать. Первое сообщение -- `futex_wait`.
* Происходит ли susperios wake up когда подключаемся через gdb? нет
* можно ли менять планировщик? ничего не поменяется
* можно ли считать состояние процесса? МОЖНО подглядеть через виртуальную файловую систему (через `progfs`). У каждого потока можно прочитать стек.

sched  nr_switches

5 ч/мес + 1 ч/день + 16 ч/час 

Альтернативные способы решения: 

* можно было запустить gdb без последующего запуска приложения.
* core dump uliit -c unlimited -- смотреть дамп без ограничений. Можно искусственно убить приложение (kill). 

Дамп ядра -- это core dump -- не ядра, а процесса.

барьерная синхронизация 21:01

== Абстракции процессора для передачи данных между кешами разных ядер  (идеальная картинка)
* Кеши 
* Брокер обмена сообщениями

Протокол поддержки конкурентности кешей -- набор ссобщений и последовательности их для поддержки когерентности (когда что-то там одинаковое).

Когда ядро хочет читать -- оно запрашивает его у брокера. Брокер передает данные из ОП с дополнением до линейки кеша процессора. Линейка соотносит адрес оп и ее содержимое.

Обычно одна линейка кеша -- 64 байта. Какой бы размер мы не считывали (даже чар) -- все равно считаем 64 байта.

Процесс инкрементировал его и продолжил работать.

То же самое значение запросило второе ядро. Просит у брокера чтение. Он понимает, что кеш этой переменной уже у какого-то процессора. Реального доступа к ОП не было, копируется линейка кеша из первого потока (уже инкрементированное!!)

image::media/2023-11-17.png[]

Начинается проблема: данные не согласованы. Втрой поток икрементирует значение до 3. Теперь одни и те же данные в 3 состояниях. Чтобы это корерктно обрабатывалось существует протокол поддержки когерентности кешей процессов.

=== MESI
Вообще их много разных, мы рассмотрим учебный пример MESI (4 состояния, в релаьном около  20).

Добавляет к каждой линейке кеша состояние этой линейки -> 2 бита.

image::2023-11-17T18-41-47-097Z.png[] 

Когда первый процессор запросил -- кеш в состоянии I - invalidate

Когда только считали -- E -- exclusive. Оно только у этого процессора и не извенялось. Поэтому когда кеш будет вытеснятся алгоритмом LRU его можно не обновлять.

image::2023-11-17T18-42-25-554Z.png[] 

Изменили данные -- сотояние изменилось на modify. Теперь при LRU значения обновятся и в ОП

image:2023-11-17T18-43-49-348Z.png[] 

Когда прочитал второй процесс -- состояние изменилось на shared. Данная линейка кеша находится больше чем в 1 ядре процессора. Если никто не меняет, но оно S -- состояние все равно синхронизируется.

image:2023-11-17T18-45-07-037Z.png[] 

Второе ядро меняет с двойки на тройку. Теперь в системе у одних данных 3 значения. Когда второе ядро поменяло значение в любом бите кеша -- оно шлет всем ядрам запрос (2 объединенных) -- read invalidate. Оно говрит, что другие ядра сначала должны инвалидировать линейку кеша, а потом перечитать ее у брокера. Линейка кеша распространяется и копируется в другие ядра. Фактически ставит в invalidate и читает. Остальные ядра шлют обратно (через брокера), когда они его прочитали -- invalidation acknowledgment. Ядро-источник ждет подтверждение.

Если два ядра заходят одновременно инкрементировать тройку, брокер все равно выберет какое-то первым, а какое-то вторым. Порядок случайный. Данные, которые меняются в кешах -- не защищены примитивом синхронизации. При этом флаг "захвачен" никем не защищен и может изменяться так.

`-` ядро-отправитель джет подтверждения 

`-` ядро-получатель должен бросать свои дела и инвалидировать 

Чтобы решить эти проблемы в архитектуру процессора ввели специальные аппаратные элементы.

* *store buffer* -- флаг, что еще не вссе прислали подтверждение. поток-отправитель продолжает работать, но на неподтвержденную линейку кеша наложены ограничения. 
* *invalidate queue* -- очередь на инвалидацию для одного процессора. будет отработан не сразу. подтверждение отправляется не сразу, а когда запрос будет добавлен в очередь. 

image:2023-11-17T18-57-36-473Z.png[] 

Барьер памяти -- просто ассемблерная инструкция ,которая применяется к одному из процессов smp_rmb -- read memory barrier, smp_rwb, smp_rmb -- read & write. И предлагает ему честно ждать одну из очередей.

image:2023-11-17T19-06-24-210Z.png[] 

image:2023-11-17T19-06-38-800Z.png[] 