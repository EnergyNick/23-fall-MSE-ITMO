= Память

== Теоретические барьеры памяти  
Все барьеры применяются только на одном ядре! Налаживаем частичный порядок работы (с кешами) в каждом из потоков и таким образом в целом что-то хорошее выходит.

Бумажные конспекты 

== Модель памяти
Модель памяти -- набор барьеров, которые автоматически гарантирует конкретная архитектура или и иной уровень абстракции (наиболее высокий уровень абстракции).

Модель памяти может гарантироваться: 

* архитектурой процессора
* фреймворком 
* языком программирования высокого уровня (должна гарантировать на всех машинах независимо от модели памяти архитектуры, на котором будет исполняться код)

=== 1. Sequential consistency
Любая операция и чтения и записи приводит к применению всех 4 барьеров памяти. 

Если какой-то процессор предоставляет его, то у него нет ни `Store Buffer` ни `Invalidate Queue`. Он всегда работает честно.


=== 2. Strong order (TSO -- total store ordering), сильная модель памяти
Бесплатно предоставляет `acquire/release` семантики. Т.е. не использует `StoreLoad`. 

Пример: AMD64 (синоним X86_64), X86 (она для 32 битной)

Пример, который не покроет `acquire/release` семантика.

```x = y = true```

Поток 1

```kotlin
fun f(){
    x = false
    assert(y)
}
```

Поток 2

```kotlin
fun f(){
    y = false
    assert(x)
}
```

Чтобы разрешить это -- нужно использовать `StoreLoad`. В AMD как раз так, он допускает reordering в случаях StoreLoad,  т.е. такие случаи нужно указывать явно.

Нормальное поведение -- один из assert упадет.

=== 3. Weak ordered (Слабая модель)
Архитектура/ЯП заставляет явным образом задумываться о всех 4 барьерах памяти. Ни один не поддерживается! Нужны все явно.

Пример: ARM v7. Средняя производительность выше при той же частоте, но больше ошибок.


=== 4. Super-weak 
Есть возможность перестановки инструкций зависимых по данным в одном потоке (можно переставить местами вторую и третью строки).

Пример: Alpha

```cpp 
int * x;
x = new int(20);
*x = 5;
```
== Примеры 
=== jre 
При работе с volatile компилятор в байткод анализирует код и ставит один из барьеров. Затем для каждой архитектуры оно реализуется по-своему.

Реализует слабую модель памяти.

=== Нативные ЯП 
В c++ atomic `load` и `store` модель памяти передается как аргумент (та, которую мы хотим). По умолчанию -- самая сильная модель памяти. Может это и не оптимально, но безошибочно.

Можно без атомиков явно взять и поставить барьер памяти посередине кода.

consume -- StoreLoad -- самый ядерный барьер, и invalidate cash чистить и Store Buffer. Метод fence (?).

relaxed -- расслабиться и не применять ничего. Без барьеров памяти!!! Чистое чтение/запись. Имеет смысл, если на каком-то этапе работы приложения переменная нужна в каком-то более-менее свежем состоянии (счетчик и т.д.) 

*Максимальная производительность*

isReady -- атомик флаг


Первый поток:

```cpp
void f(){
    data = 42;
    //StoreStore -- release
    ready.store(true, ?);
}
```

Второй поток:

```cpp
void g(){
    if(ready.load(?)){
        //LoadLoad -- acquire
        assert(data == 42);
    }
}
```

Это максимально производительный код на CPP.

Почему не дали отдельно барьеры памяти? Не на все архитектуры и языки можно реализовать отдельно что-то. На плюсах 

== Неявное применение барьеров памяти

Даже не зная о барьерах памяти, мы применяем их 

* Примитивы синхронизации. Иначе нельзя: у примитива есть флаг, который разделяется между разными потоками.
* смена контекста потока, окончание планирования (как производные -- sys_call, join и т.д.). Почему? Ответственность за подчисткой контекста на выжившем потоке(?).

atomic (lock-free алгоритмы и т.д.) применяют их явно.

volatile в java -- способ явного указания для использования барьеров памяти. В с++ volatile никакого отношения к барьерам памяти не имеют.