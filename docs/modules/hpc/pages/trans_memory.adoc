= 11. Транзакционная память 

Проблемы lock-free алгоритмов 

image::trans_memory/locking_2_problems.png[]

Транзакции 

* начинаем
* делаем несколько операций 
* заканчиваем (с успехом или неуспехом)

У нас это логическая операция, которая выполняется либо вся полностью, либо не выполняется ни одна из ее строк.

== Пример ORM 

image::trans_memory/orm.png[]

С помощью orm из БД выбираем список студентов (SELECT). Выставляем ему оценку и сохраняем (SELECT). Сначала идет повторный select, orm проверяет что изменилось, а что нет и только после этого обновляем (те, что действительно изменились).

Когда мы длительное время работаем над данными, то транзакцию не держим в ORM (иначе никто не сможет с ними работать). Технически держать транзакцию от начала до конца можно. Но тогда будут проблемы с синхронизацией.

Это похоже на lock-free (на уровне orm)

[.minuses]
* алгоритмика 
* согласованность 

[.pluses]
* производительность

=== Software transaction emmeory

image::trans_memory/stm.png[]

Аналог с транзакционной памятью: У нас есть приложение и RAM. Мы ходим какой-то менеджер памяти, который пытается атомарно записать транзакцию в RAM.

image::trans_memory/app_trans.png[] 

Концепция реализована здесь: в блоке atomic говорим о том, что работа должна быть транзакционной. 

image::trans_memory/java_trans_mem.png[]

В Haskell транзакционная работа с памятью релаизована на уровне языка.

Contention -- пересечение по RAM и др ресурсам между несоклькими потоками


image::trans_memory/pluses.png[]

* мы говорим, ЧТО мы хотим сделать. Но не уточняем как, т.е. примитивы синхронизации и проч. определяются под капотом.
* лучшая утилизация ресурсов -- заранее знаем, где потенциальный contention. Java 
* если все хорошо -- накладные расходы дб невелики. Алгоритмы должны отрабатывать только при пересечении  
* 

=== Hardware transaction memory

image::trans_memory/htm.png[]


Если в блоке atomic начинается обращение к памяти, то к записи в линейки кеша процессора дописывается еще один бит. 

На что он влияет? Когда любой другой поток работает с той же самой линейкой памяти и линейка в состоянии s (shared) и один поток добавил его в atomic режиме. Если другой поток его поменял и начал распространять, то когда изменения придут к процессору с транзакйией -- её можно сразу прервать и начать заново.

Как бы код выше должен был быть преобразован компиляторам: 

image::trans_memory/realization.png[]

==== Ограничения  
Транзакция по времени должна быть ограничена квантом планирования ОС. Когда поток уйдет с исполнения -- то всем уже все равно, что там было в кешах. И объем данные, используемых транзакцией, должен помещаться в кеш первого уровня. И никакие линейки кеша не должны вытесняться из кеша!

image::trans_memory/ogr.png[]

==== Производительность 
скип лист, операций в секунду 

по y  -- количество потоков 

image::trans_memory/prod.png[]

==== Пример с++ 

image::trans_memory/cpp_info.png[]

Примеры для C++. В стандарте пока нет. Ключевые слова разные, т.к. разные версии GCC

image::trans_memory/exp0.png[]

image::trans_memory/exp1.png[]

Тут даже данные в вызываемых функциях защищены транзакцией! Но в конкретном примере скорее всего упадем, т.к. целых 2 вызова `std::cout`

==== Обработка ошибок 

image::trans_memory/errors.png[] 

Для каждого кода ошибки можно указать как мы будем ее обрабатывать.

==== lock free через TM  
TM в целом не гарантирует lock-free, но если это HTM -- то в большинстве случаем да.

== Процессоры 
Hardware Transaction Memory -- это расширение процессора `TSX`. Его можно выключить микрокодом при загрузке ОС. При желании, включить тоже можно.



[.pluses]
* идея красивая 
* производительность 

[.minuses]
* В некоторых линейках процессора падает с UB или зависанием системы! Это аппаратные ошибки, которые софтом не решить. Это плохо для промышленного программирования. 
* Intel отключили их на процессорах из-за ошибки 2022 года. Ошибки падают, например, при использовании pmu для профилирования другой программы, которая использует транзакционную память. 
* Будущее туманно. В основном академические исследования.

== Lock teleportation 
Как оптимизировать тонкую синхронизацию (fine graned) с помощью TM

* Захватили два первых элемента
* Начали транзакцию
* Прыгаем на n элементов вперед без примитива синхронизации
* Захватываем синхронизацию 
* Заканчиваем транзакцию
* Если успех -- то операция тоже успешна. Мы успешно "телепортирвались" на n штук вперед. увеличиваем n на 1.
* Если неудача -- уменьшаем n на два, пытаемся снова. 

image::trans_memory/graph.png[]

TCP так же подстраивается по пропускную способность системы, выбирается "размер окна" -- сколько элементов мы отправим, пока не дождемся подтверждение первого 

Ломает ли чтение транзакцию? Можно надеется, что нет.