= 4. Алгоритмы синхронизации 

Имеем односвязный список, отсортированный по id. 

```kotlin
class Node {
    val data 
    val next
    val it

    add(id, data)
    remove(id)
    contains(id)
}
```

Работаем на одной машине в языке со сборщиком мусора. 

Хотим увеличить производительность -- количество потоков, которые могут одновременно работать со структурой.

Наша структура поддерживает безопасность добавления узлов. Она не отвечает за данные, которые там хранятся.

== 1. Грубая синхронизация (coarse-grained)

Заводим 1 примитив синхронизации.

Как сделать потокобезопасным? Захватывать. `mutex` у каждого метода.

Чуть быстрее -- `read/write mutex`.

== 2. Тонкая (fine-grained locking )
Примитив синхронизации на каждый элемент структуры данных.

Дорого по памяти (даже в java создание монитора для объекта ленивое) и времени. 

Как захватывать мониторы для разных ситуаций? 

`remove` -- удалить логически 

`delete` -- физическое освобождение 

1. *Просмотр* захватываем по 1 элементу (захватили второй -- отпустили первый).

 "пришла тысяча потоков и удалила все элементы. через год проснулись и пошли дальше, но пошли дальше по мертвечине"

2. *Добавление* `3 -> 7 (insert 3.5)`

 Захватываем 3. И все, вторым владеем не явно.
 Есть даже плюс к производительности: пока добавляем перед 7, после семерки можно добавлять параллельно. 

3. *Удаление* `3 -> 7 -> 9.5 (delete 7)`

Пусть мы захватываем 3 при удалении? Пусть два потока удаляют 7 и у обоих есть код `3.next = 9.5` 

Если второй уснул, то за время его сна после `3` могли добавиться новые элементы. Но после пробуждения он их перетрет, записав `9.5`. Поэтому почти всегда нужно захватывать элемент, у которого мутирует часть данных.

`9.5` можно не захватывать.

[.pluses]
* Новое качество структуры данных: физически параллельно в разных местах структуры могут работать разные потоки. Повышение производительности.

[.minuses]
* Заплатили памятью (mutex на каждый элемент).
* потоки не могут идти дальше, если у них на пути есть захваченный другими потоком элемент. 

== 3. Оптимистичная синхронизация  

*Удаление* `2 -> 3 -> 4 -> 5 (delete 4)`

Идем по списку без блокировки до тех мест, где нужно выполнить действие. Блокируем их (`3` и `4`). Но до этого мы ничего не захватывали и что-то могло пойти не так. Что именно? 

1. Могли добавить между ними 3.5 -> валидируем (проверяем, что 3 все еще ссылается на 4).
2. Могли удалить 3 или 4 (мы стоим на 3, а из 2 ее уже удалили).

*Валидация* : как проверить, что элементы не удалены? После захвата переменных дойти до них из начала списка. 

[.minuses]
* Могут быть потоки, у которых никогда не получается выполнить операцию ("жизнь такая")

[.pluses]
* Еще оптимальнее работаем 
* Если у кого то не получается выполнить операцию -- значит кто-то другой точно успешно выполнил ее! 


Результат `contains` гарантирует не текущее состояние структуры (это спорно в параллельном программировании), он гарантирует правду, которая была хотя бы одно мгновение между запуском программы и возвращением результата операции.

== 4. Ленивая 
 Лень идти для валидации по списку!

Оптимистичная, только второй этап валидации преобразуем: каждый элемент имеет *флаг*, удален ли он. 

Поток сначала выставляет флаг удаления (взяв блокировку), а потом перемещает ссылку (вроде порядок операций не важен).

*Валидация* -- проверка флагов удаленности. При неудаче все равно идем с начала списка.

[.minuses]
* платим памятью (битик)
* если уснет после захвата перед валидацией, то все потоки будут ожидать.

[.pluses]
* для валидации смотрим не всю структуру с начала 

== 5. Lock free (неблокирующие)

Если в приложении n потоков, решающих разные задачи -- `lock free` реализация гарантирует, что останавливая в произвольный момент времени k потоков -- остальные n-k гарантировано завершат свои задачи. Т.е. потоки вообще не зависят друг от друга.

 
*Добавление* `1 -> 2 -> 3 -> 4` + `2.7`

Изначально узел 2 = {next: 3, deleted: false}

Если next -- что-то, к чему можно применить CAS (Java - atomic reference, C++ -- atomic ptr), то достаточно вызвать у него метод:

`2.cas({3, false}, {2.7, false})`

Если этот cas получается, то добавляем элемент: перекидываем ссылку, если элемент не удален.

В `C++` либо `doubleCas`, либо выделить один из битов адреса переменной под флаг -- удален ли. Есть в boost, есть в libcds, hpx, folly (facebook). Там есть на что посмотреть.

В `Java` -- `java.util.concurrent` -- `AtomicReference`, `AtomicMarkableReference` (atomic + bool), AtomicStampedRef (atomic + int). Но эти структуры могут быть неэффективно реализованы для определенных платформ.


*Удаление*
Первый кас -- установить флаг.

Второй кас -- изменить ссылку. Если после первого каса кто-то добавил элемент, то беда.

Поток, который добавляет может "помочь": перекинуть ссылку за удаляющий поток, а потом выполнить свою операцию. Если этого не сделать, то не будет lock-free!!

Если cas неудачный, то начинаем все с головы списка.

Если кто-то постоянно не может выполнить свое действие, то нам все равно: это происходит в нашем же процессе и нам интересна средняя успешность. Иногда в предметной области это можно решить, но за счет снижения общей производительности (это как мигалки на дорогах).

[.pluses]
* потоки друг от друга не зависят
* гарантируют постоянный прогресс системы: с каждым cas мы выполняем какую-то новую задачу
* часто используется в брокерах (на шинах данных) в ОС или встраиваемых системах. 

 Пример: dpi - de packed inspection -- блок между нами и интернетом, который анализирует наш трафик (у РКН, например). Обычно это 24 ядра процессор с lock-free алгоритмом, который обеспечивает высокую пропускную способность. При этом пользователи не должны узнать, что что-то не так.

[.minuses]
* сложно реализовывать, нужно думать
* в некоторых синхронизациях тонкая синхронизация успешнее (cas медленный, нагрузка на систему в области не большая)


== ABA' problem

 Специфичная для lock-free. Пишем на нативном языке программирования (без сборки мусора: плюсы, паскаль, делфи, ассемблер). На языках программирования со сборщиком мусора такой проблемы нет.

Пишем lock-free стек.

На верхушке стека лежит данные `A`. Есть два потока, работающих со стеком: p1, p2;

`T* m_top` -- вершина стека.

`push` особенный -- добавляет данные только определенного рода.  

Поток 1:

```c++
void push(){
    T* top = m_top;
    //...
    //sleep
}
```


Поток 2: 

```c++
pop();      //remove A
push(B);
```

Аллокатор памяти с высокой вероятностью соптимизирует и `В` положит по старому адресу `А` 

Поток 1:
```c++
//...
//sleep
cas(m_top, top, newValue)
///if(m_top == top)
///  m_top = newValue
```
Второй поток думает, что там `А`, но там `В` и могло быть такое, что снимать `В` со стека категорически нельзя, и это приведет к запуску ракет. Но поток думает, что там объект типа А (отсюда второе А' в названии), хотя он уже В.

Проблема в том, что мы считаем, что если адреса одинаковые, то и значение в них одинаковые.

=== Решение (SMR)

 Поняли, что не можем писать безопасные алгоритмы на С++

Умные указатели. Объект бы не удалился и аллокатор не сделал бы гадость. К сожалению, это указатель и счетчик ссылок. Обычно это две переменные. Что менять первым: указатель или счетчик ссылок? Это уже не lock-free. У Уильямса описано как реализовывать cas на shred-ptr.

*SMR* -- safe memory reclamation scheme

1. *tagged pointers* -- аллокатор в адресе при каждой итерации инкрементирует свободные 16 бит. Поэтому cas будет не проходить. 
** ошибка может пройти, когда 16 бит переполнится 
** `Z-series` (архитектура процессоров, используется в основном в страиваемых системах). Но это не важно. Важно, что не мультиплатформенно.
** не все биты для каждой ОС могут быть использованы

2. *gc* -- написать свой сборщик мусора конкретно для этой структуры данных. 

3. *hazard ptr* (на пальцах, красивый)
** говорим, что у нас есть некоторое количество `hp` (`hazard ptr`) для структуры данных. Их число обычно совпадает с количеством примитивов синхронизации, которое нужно захватывать при тонкой синхронизации -- это инвариант структуры данных.
** имеем для каждого потока некоторое количество опасных указателей (это прям отдельный тип).
** удаление: выделяется доп структура данных для хранения `retired` указателей: мы с ними не работаем, но не понятно, работает ли кто-то еще. Размер фиксирован: количество потоков * количество hp для потока. Доказано, что она не растет.
** Когда все перестают ссылаться на опасный физический указатель, то последний поток освобождает его из retired хранилища.

== Extra 

* Верно ли что если алгоритм реализован только на cas операциях -- он lock-free? 
 
 нет, т.к. `spinlock` -- реализован на `cas`, но это `mutex`

* Верно ли, что если `lock free`, то используем только `cas`?

 Да или похожие ассемблерные инструкции и примитивы (на некоторых процессорах не x86 этого нет)
