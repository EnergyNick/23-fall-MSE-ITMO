= 9. Flat-Combining

image::flat_combine/2024-01-25-20-41-30.png[]

== 1. Treiber

Наиболее прострая структура данный, которую можно сделать lock free

Одна точка входа

image::flat_combine/traiber_impl.png[]

image::flat_combine/traiber_impl2.png[]

== 2. Линеализуемость 
Результат ЛЮБОГО исполнения параллельного кода соответствует хотя бы ОДНОМУ последовательному исполнению. 

image::flat_combine/definition.png[]

image::flat_combine/line.png[]

Есть атомарный счетчик. Вызываем функцию, которая ее инкрементирует  и возвращает.
По оси y -- время  

image::flat_combine/error.png[] 

корретное 

image::flat_combine/correct.png[]

Правда ли, что в 

Точка линериализации -- кас, который делает изменения видимимы другим потокам.

image::flat_combine/2024-01-25-21-05-18.png[]

== traiber & line 
Точки линерализации -- кас или точки взаимодействия с общей памятью.

Когда кладем -- такая точка одна

image::flat_combine/tr_line1.png[]

Когда вынимаем -- таких точек 2

image::flat_combine/tr_pop.png[]

== michael-scott 

Делаем локфри очередб. 

image::flat_combine/ms1.png[]

Имеем 2 ссылки голова, хвост. И всегда существующий в списке элемент senitel -- вечно живущая голова.

Добавление элемента (таракан его принес )

image::flat_combine/ms2.png[]

image::flat_combine/2024-01-25-21-08-21.png[]

Добавляем cas элемент в конец очереди

image::flat_combine/2024-01-25-21-08-26.png[]

Если другой поток захочет добавить элемент в конец. Если он пойдет через хвост -- это будет не последний элемент. Дальше есть две стратегии 

1. Этот поток сам фиксит хвост текущий, помогая другим потокам, и идет добавлять свои данные (сам алгоритм)
2. Каждый поток фиксит только свой хвост.


image::flat_combine/2024-01-25-21-10-13.png[]

Каждый поток, который делает вставку проверяет, не нужно ли пофиксить хвост. Хвост -- элемент с ненулевым следующим указателем. 

Добавляющий элемент сперва фиксит хвост, если это кому-то нужно, и лишь затем вставляет. Если этого не сделать, то мы и вставку сделать не сможем -- хвоста (элемента с нулевым указателем больше нет). 

Фиксить нужно обязательно, иначе поток исправляющий хвост может заснуть на год.

=== извлекаем элемент

Состояние до каса 

image::flat_combine/2024-01-25-21-22-04.png[]

1 кас: следующий за головой элемент делаем головой. Извлекаем из новой головы данные. При гете все равно нужны только данные! 

Старую голову соберет сборщик мусора.

image::flat_combine/get.png[]

Производительность:

* актуальный хвост быстрее, иначе все потоки через всю очередь идет
* проверки на пустоту вида `head != tail` не работают

Корректность: если все добавили элемент в "лесенку" и заснули перед касом на хвост, то когда они будут просыпаться и пытаться починить хвост -- он может бы не поправлен вообще. Если самый верхний поток уже исправил, то все остальные проснувшиеся уже не смогут! 

Логическая ошибка: если мы не будем фиксить хвост при каждом удалении, то голова может указывать на данные, которые идут после хвоста! Но в целом в этом нет проблем, если при добавлении мы учитываем, что пропускаем элементы без данных. 

== алгоритм 
image::flat_combine/2024-01-25-21-33-22.png[]

В else -- помогаем чинить чужой хвост. в ифе чиним свой.

Если нужно пофиксить хвост -- пытаемся. Если не получается -- идем дальше. Фактически, переменная от фактического хвоста никогда не буде отличаться больше чем на 1, т.к. если у нас не получилось -- значит у кого-то другого получилось.

=== Главная идея 
Если в алгоритме за 1 шаг больше одного каса, то без хелпера не обойтись. Так как мы можем уснуть после первого каса до второго. И это уже не lock free.

== Flat combine 

Есть потокоопасная сложная-сложная программа. У нее есть интерфейс с методами push, bath_push (добавить пачкой, обычно быстрее). 

Захотели сделать потокобезопасной. 

1. Переписываем годы на lock free.  -- годы 
2. float combine

имеем объект, который внутри себя агрегирует структуру данных, а во вне предоставляет интерфейс доступа не характерный для изначальной структуры, а типа `do_operation` с типом операции и аргументов. Можно сделать еще один фасад, который дергает методы изначалььной структуры через do_operation

Суть -- когда поток делает do_operation он может джелать это потокобезопасно из несколькиз потоков. 

До начала работы со стуктурой данных регистрируем поток в структуре FC. Внутри fc существует список, который содержит по 1 элементу на каждый поток. Это список публикаций  операций. Там хранится TLS каждого потока. 

Когда наинаем выполнять операцию -- публикуем, что хотим ее выполнить в свой TLS 

op.type = x 

args = y

Пытаюсь захватить примитив синхронизации, который 1 лежит в FC (try_lock, тип примитива неважен)

И если у меня получается -- я как поток становлюсь потоком комбайнером (ТОЛЬКО 1 ПОТОК В ЕДИНИЦУ ВРЕМЕНИ МОЖЕТ БЫТЬ КОМБАЙНЕРОМ) и выполняю все операции из списка за все потоки. Если не получается -- я просто жду, пока кто-то выолнит опубликованную мной операции (spin_lock или wait).

А что если комбайнер выполнил операции, но не увидел нашу? Когда нас будят мы можем посмтореть, по какому флагу -- наши данные готовы или просто старый комбайнер уснул. Если данные еще не готовы -- то мы новый комбайнер!


Чем это лучше грубой синхронизации? 

По y операций в секунду

По х количество потоков

image::flat_combine/stat.png[]

количество кас, которые провалились на каждую операцию

image::flat_combine/stat2.png[]

кеш мисов гораздо меньше, т.к. операции скорее всего над одними данными (исходной структуры) и они уже скорее всего в кеше НАШЕГО потока.


image::flat_combine/stat3.png[]

Сверху на SPARK (пропускная способность очереди с приоритетами)

image::flat_combine/stat4.png[]

[.pluses]
* чуть лучше сингл тред пула 
** комбайнер -- один из потоков-исполнителей, контекст не переключается 
** очередь задач динамическая. А здесь фиксированная и в TLS -- очень быстро обходится
* локальность кеша 
* аннигиляции/оптимизации над структурой данных ** если видим подряд push и pop, то просто перекладываем данные без обращения к самой структуры данных
** batch push -- проходимся по всем операциям, собираем пачку элементов на вставку и добавляем их пачкой (если это быстрее)
* Интенсивно работает комбайнер. Если поток часто спит, то может попасть в опалу планировщика задач. А этому будут давать больше времени, чтобы работать больше. "Кто везет -- на том и едут".

