= LD preload 

== Задачка

Задача: есть программа на тысячу строк. Заказчик считает, что программа работает медленно. Нам нужно ускорить данную программу на столько, на сколько это возможно. Или сказать, что это невозможно.

Что будем делать? 

Профилируем. `valgring` -- профилирует системные вызовы и любые ассемблерные инструкции, т.к. все инструкции выполняет в своей VM. Отобразим его результат графически `KCachegrind`

Видим, что больше всего времени занимает генерация случайных чисел в цикле. Хотим заменить на стандартное. Тратим человекоминуту и улучшаем на наносекунду.

Скомпилировали со всеми возможными флагами оптимизации и увеличили на 0.05%.

Смотрим на код, параллелим цикл, который работает константное число раз. Становится на 3-4 тысячных процента лучше.

Практический совет: удалить весь код с логикой и посмотреть, сколько программа работает без него. Ускорим на одну сотую долю процента!

`time ./diff` выдаёт 3 значения:

** real -- астрономическое время 
** user -- процессорное время (умноженное на количество процессоров), выполняющееся в user-space 
** sys -- то же самое, но в kernel-space 

Результаты: 

* real : 3,83s 
* user : 0,83s 
* sys : 0,0s

Вывод: чего-то ждем. Поищем в коде. Нашли sleep(1000)! Его не было в профилировщике valgrind, т.к. он смотрел на процессорное время, а sleep его не занимает. А еще он работает однопоточно. 

С помощью команды time мы поняли, что `bottle neck` не в процессорном времени. 

=== strace ./foo 

Мы смогли бы найти, что mutex ждет какое-то время и увидеть системные вызовы.

== О профилировщиках 

Производительность: valgring может замедлить до 120 раз (от минуты до двух часов). Это крайне дорого для промышленной разработке. Семплирующие профилировщики замедляют на десятки процентов.

Какие есть профилировщики:
* valgrind -- почти не используется в проде
* JMC -- для jvm
* profiler in IDE
* perf -- для производительности

=== Семплирующие профилировщики 

Не являются VM.

Периодически делают снимки программы, собирая статистики.

* parallel studio 
* vtune 
* perf

== Рантайм загрузчик 

=== Пример: проблема одинаковых сигнатур функций
Две команды независимо пишут код 

.a.cpp
```cpp 
//не объявлена в заголовке
foo(){
    std::cout << "a";
}

//объявлена в заголовке
do_a(){
    foo();
}
```

.b.cpp
```cpp 
//не объявлена в заголовке
foo(){
    std::cout << "b";
}

//объявлена в заголовке
do_b(){
    foo();
}
```

a компилируется в a.so, b компилируется в b.so

.main.cpp  
```cpp 
int main(){
    do_a();
    do_b();
}
```

`g++ main.cpp -lb -la`

Что произойдет? 

* соберется 
* не соберется, будет рантайм ошибка 
* Выведет в консоль:
** a b 
** a a
** b b
** b a   

Правильный ответ: Выведет в консоль `b b`

=== Загрузчик исполняемого файла 

Когда пишем ./a.out вызывается runtime загрузчик (загрузчик исполняемого файла)

* берет исполняемый файл и грузит в RAM
* берет LDD и ищет какие динамические библиотеки ему нужно подгрузить, чтобы программа работала

Если библиотеки находятся на одном уровне (не зависят друг от друга). То они будут загружены в том же порядке, в котором указаны в команде линковки.

У каждого elf файла есть таблица разделяемых символов, в которых определены используемые функции и переменные. Там их замангленные имена (если C++). Есть столбец, где указано, что этот символ определен в этом эльфе или его нужно загружать из другого.

Если не определены в моем файле, то определены как WEAK (слабое связывание). Её код нужно искать в другом месте.

Если global, то функция и объявлена и определена в текущем исполняемом файле. 

Загрузчик формирует таблицу, в которой слева -- все символы, а справа -- их адреса в памяти. 

Заполнение этой таблицы:

1. Если символ определен в этом файле -- просто пишем его. 
2. Если его нет -- у всех библиотек, которые были указаны при линковке, ищем его первое вхождение.

С точки зрения дизайна кода пример выше был с ошибкой. Как исправить? 

* Добавить функцию в анонимный неймспейс -- в качестве его имени сгенерируется случайная строка и имена будут разные. Но такая случайность не подходит для спецификации кода (контрольная сумма кода будет разная!). Чтобы это поправить -- в компилятор можно передать сид для генератора случайных строк, чтобы генерация была одинаковой.
* Добавить функции ключевое слово static 

== LD_PRELOAD

=== Пример

Есть программа, которая куда-то пишет. Делаем свою разделяемую библиотеку. Делаем в ней функцию, которая дублирует сигнатуру функции write.

spy.so
```cpp
write(...){
    send_data(GRU);
    //вызвать конкретный write из конкретной библиотеки с конкретными параметрами 
} 
```

LD_PRELOAD = srt.so

Теперь при загрузке любых библиотек первым будет загружаться spy.so и все функции сперва будут искаться в ней. Поэтому мы сможем подменить стандартные функции. И, например, воровать все данные из write и отправлять их себе на почту.

На основе LD_PRELOAD работает часть семплирующих профилировщиков: все syscall оборачиваются функциями профилировщика. Поэтому программы не нужно перекомпилировать. 

Если нет системных вызовов? Профилировщик будет собирать информацию с процессора и т.д.

Зачем эти функции в профилировщике? Теперь при любом вызове функции мы можем делать снепшот стека вызовов и т.д.

В какой области запускаем его? В user space, в kernel space -- может и можно, но инфраструктурно это очень затратное мероприятие.


== Vtune (usually for Intel)

=== Hotspots -- время процессора

image::12/2024-01-23-20-08-17.png[]

=== threading 
image::12/2024-01-23-20-08-54.png[]

Нам сразу говорят, что эффективное время процессора 0.05% 

В графовом предаствлении непроцессорные вещи тоже указаны (sleep)

image::12/2024-01-23-20-10-37.png[]

==== Timeline 
Временная шкала со всеми событиями данного потока.

image::12/2024-01-23-20-12-39.png[]

=== Performance snapshot 

Показывает какие методы профилирования потенциально могут быть полезны для данного кода

image::12/2024-01-23-20-11-33.png[]

=== Time interval  
Часто у приложений есть время загрузки данных или периоды пиковой нагрузки процессора. Поэтому бывает интересно смотреть только на ту часть интервала, которое не удовлетворяет SLA. Можно вывести статистику только по этому участку. 

image::12/2024-01-23-20-15-16.png[]

 SLA - service layer agreedment -- соглашение об уровне сервиса (на какую нагрузку гарантированно способно наше приложение).

=== Многопоточность 
Время исполнения/ожидания для каждого потока
image::12/2024-01-23-20-16-28.png[]

Взаимодействие через потоки через примитивы синхронизации 

image::12/2024-01-23-20-17-21.png[]

Масштаб побольше

image::12/2024-01-23-20-18-42.png[]

Через этот инструмент можно проверить, что приложение ведет себя так, как было задумано. Например, что нет всегда спящих потоков.

== Профилирования работы с памятью  (memory access)
Это редкий случай. Его не имеет смысл проверять, если не были проведены предыдущие способы профилировки.

Программа:

image::12/2024-01-23-20-56-04.png[]

image::12/2024-01-23-20-57-21.png[]

Функция суммирует все элементы матриц. Первая сначала по строчкам, затем по столбцам. Вторая -- наоборот. 

=== Эксперименты
Скомпилировали в дебаге без оптимизаций.

==== Колонки в debug (-O0 -g)

image::12/cols-debug.png[]

Заняло 5 секунд

==== Строчки debug

image::12/lines-debug.png[]

==== Колонки release (-O3)

image::12/cols-release.png[]

==== Строчки debug 
image::12/lines-release.png[]


== Метрики Memory Access 

Как следует интерпретировать результаты?

* LLC Miss Count -- last (?) cache. Имеет смысл в рамках одного кванта планирования ядра ОС.

Сравним результаты у разных замеров 

Как сравнивать: 

image::12/compare_results.png[] 

Результаты сравнения: 

image::12/compare_release.png[]

=== Cache miss & bound

Cache miss у строчек вообще нет. Из высоких cache miss у второго, вытекают высокие `bound`. 
====
bound - как долго процессорное время тратится здесь. Чем меньше - тем лучше.
====

Хотим посмотреть в какой строчке cache miss происходит чаще всего. Для этого нужно включить дополнительные галочки.

image::12/miss_statistic.png[]

===  CPI Rate 
Показывает насколько потенциально можно ускорить приложения, не меняя алгоритм, а эффективнее расходовать память 

image::12/cpi_rate.png[75%]

За один цикл процессора мб сделано 4 инструкции процессора (определяется архитектурой). Если программа написана так, что в каждый такт все эти 4 инструкции будут сразу выполняться (все данные уже лежат в кешах!), то метрика будет идеальной.

Идеальное значение метрики -- 0.25, это 0.25 цикла на 1 инструкцию. Если она больше 1 -- то есть явные проблемы с доступом памяти в приложении. Значит можно сравнительно небольшими усилиями понять где это происходит (где cache miss) и реорганизовать код.

== Зачем профилировать? 
* Увеличить производительность.
* Значительно сэкономить ресурсы.
* Еще бывает профилирование энергопотребления. Это нужно для мобильных приложений и их виртуальных машин.


Можно профилировать, запоминая данные из CI. Добавлять само профилирование в CI обычно не целесообразно, очень много ресурсов потребляет.

Коридор производительности -- производительность тестов не должна меняться на x процентов от запуска к запуску.

== Утечки памяти 
Профилирование -- это анализ производительности. 

Утечки памяти -- это анализ памяти, он обычно выполняется сторонними утилитами. Сейчас эту функцию выполняет санитайзер, который обычно встроен в компилятор. Но можно использовать memcheck valgrind. 

Для jvm можно раз в час снимать снепшоты и смотреть на то, какие объекты появились.