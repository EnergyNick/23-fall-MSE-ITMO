= Intel TBB  

Открытая библиотека. Качество кода и стабильность кардинально выше, чем у OpenCV (библиотека обработки изображений).

В отличии от omp, это библиотека общего назначения для профессиональных разработчиков для высокопроизводительных, эффективных и нетривиальных архитектурных решений.

[NOTE]
====
Есть только для c++
====

== Состав

Иногда ее называют STL параллельного программирования.

image::13_tbb/tbb_struct.png[]

=== Примитивы синхронизации

Сделана до стандарта std::11, когда еще не было стандартных примитивов синхронизации, от чего в библиотеке они задублированы (часть deprecated).

image::13_tbb/sync.png[]

=== Параллельные алгоритмы 

image::13_tbb/algo.png[]

Нет возможности создать больше одного пула потоков на весь процесс, т.к. он скрыт. Уровень абстракции выше, чем у omp -- здесь он на уровне задач, а не на уровне потока.

Думаем в терминах -- у меня есть задача, я отдаю ее на исполнение и получаю результат. А как она будет исполняться -- скрыто планировщиком tbb (чем-то похож на fork-join pool в java).

У каждого потока своя независимая очередь задач, которая реализуется в виде дека. Набор очередей задач балансируются. 

Любое действие в tbb всегда преобразуется к базовому классу tbb:task.

Балансировки могут быть реализованы разными алгоритмами. Один из них *work stealing* -- когда поток сделал свои задачи, то крадет часть задач из конца дека другого. 
====
Почему крадем несколько задач у одного потока, а не по одному у разных? Когда появляется очередь задач, то она скорее всего получена из рекурсивных запросов. Есть мы возьмем последовательный кусок, то высока вероятность, что эти задачи будут обращаться в близкую область памяти и будет меньше промахов кеша.  
====

Код тасок все равно должен быть потокобезопасным!

==== Пример алгоритма

blocked_range:

* разбивает массив на диапазоны
* каждый диапазон выполняется своим потоком
* диапазон может быть двух и трехмерным -- это мб полезно для обработки 3D сцен

image::13_tbb/parallel_for.png[]

==== Абстракции уровня деревьев задач 

image::13_tbb/fib_task.png[]

====
* spawn -- отправить на исполнение 
* spawn_and_wait_for_all(a) -- ожидание исполнения задачи, но технически поток продолжает выполнение других задач. Похоже на fj_pool + completable_feature из Java
====

image::13_tbb/fib_code.png[]

Если мы занимаемся не сортировкой, а поиском, то можем отменять все задачи от родителя, когда найдем ответ.

==== parallel pipeline 

Настраиваем пайплайн обработки данных, где каждый элемент пайпа обрабатывается в разных потоках. Если пайп определяет, что какой-то участок перегружен, то создаются копии логики в отдельных потоках. 

==== parallel_do

Подходит для вечной обработки событий (игры, например).

=== Аллокаторы памяти 

image::13_tbb/mem_alloc.png[]

Какие проблемы могут быть с аллокаторами с точки зрения производительности? 

==== *False sharing* 

Пример непрофессионального разработчика.

Пусть у нас есть двухъядерная машина и массив 32-байтных структур.

Распаралеллим их обработку. Пусть первый поток обрабатывает все нечетные элементы, а второй -- все четные. 

У нас два ядра, а значит у каждого свой кеш, с линейкой кэша размера 64 байта. Когда первый поток загрузит первый элемент, то он загрузит и второй. Второй поток аналогично загрузит первый и второй элемент в кэш. Из-за когерентности кэшей, они при каждой модификации будут синхронизироваться между ядрами. 

image::13_tbb/sharing.png[]

Это может работать медленнее, чем обработка на одном ядре.

==== *cache_aligned_allocator*

Решение предыдущей проблемы. Возьмем cache_aligned_allocator, который сделает так, чтобы объект занимал кратный размеру кеша объем памяти.

==== *scalable allocator* 

Синхронизированный аллокатор может убить даже лок фри, пока мы будем ждать выделение памяти конкретному объекту.

Решение:
Аллокатор для каждого потока, который первый раз запрашивает память, создает свой участок памяти. 

На каждый запрос от потока аллокатор выделяет ему память в отведенном участке. Поэтому этот алгоритм выделения может работать для разных потоков одновременно. 

Уже есть реализации таких аллокаторов. Может приводить к росту производительности на десятки процентов.

Мы можем даже подменить глобальный аллокатор (обычный new или malloc). Сделать это мы можем через `LD_PRELOAD`, не перекомпилируя приложения.

== Flow graph

Позволяет строить логическое представление программы 

image::13_tbb/flow_1.png[]

Пример графа:

image::13_tbb/flow_2.png[]
====
Функции в кружочке -- написанный нами код.
====

Пример создания графа в коде:

image::13_tbb/flow_ex1.png[]

Если не будет узла, который бесконечно продуцирует данные -- мы закончим выполнение. Иначе зациклимся.

Зачем нужен? 

Мы делаем не просто пайплайн, а делаем все описание задачи, которое отдаем на исполнение. Это позволяет делать глобальную балансировку нагрузки.

Еще в нем предусмотрены всякие фишки 

* пусть в одном из узлов нужно обрабатывать изображение -- смотреть последовательные кадры. Если узел перед ним распаралелен, то кадры будут не по порядку. Поэтому данные можно анотировать (номером по порядку). Перед входом в узел можно отсортировать эти данные.
* такие графы можно запускать и профилировать

image::13_tbb/graph_profile.png[]


=== Куда развиваются 

* каждые полгода появляется новый тип узла графа 
** асинхронные 
** `opencl_node` -- гетерогенные вычисление -- синоним `offload` (миграция вычислений).

=== Вывод

[.minuses]
* отпугивает своей мощью программистов

[.pluses]
* хороша, когда нужно построить pipeline приложения с нетривиальной обработкой нагрузки.
* стабильная, отлаженная.

Чтобы использовать такие мощные абстрактные вычисления нужны мощные абстрактные задачи (игровые движки).

`opm` и `tbb` находятся на разных уровнях абстракции с точки зрения мышления. Но использовать их стоит только в подходящих случаях. 